{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploying PyTorch Model in Python via a REST API with FLASK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachinkun21/PyTorch/blob/master/Deploying_PyTorch_Model_in_Python_via_a_REST_API_with_FLASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuxiANnBU5me",
        "colab_type": "text"
      },
      "source": [
        "In this Notebook, I will deploy a PyTorch model using Flask and expose a REST API for model inference. In particular, we will deploy a pretrained DenseNet 121 model which detects the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dffHqANZVIo0",
        "colab_type": "text"
      },
      "source": [
        "This represents the first in a series of tutorials on deploying PyTorch models in production. Using Flask in this way is by far the easiest way to start serving your PyTorch models, but it will not work for a use case with high performance requirements. For that:\n",
        "\n",
        "- If you’re already familiar with TorchScript, you can jump straight into Loading a TorchScript Model in C++ tutorial.\n",
        "- If you first need a refresher on TorchScript, check out Intro a TorchScript tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT9JEikoVTMC",
        "colab_type": "text"
      },
      "source": [
        "### **Step1: API Definition**\n",
        "We will first define our API endpoints, the request and response types. Our API endpoint will be at /predict which takes HTTP POST requests with a file parameter which contains the image. The response will be of JSON response containing the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pb0YHVYUNsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "332d7796-70d8-4941-bcbc-4e5b508d4a2c"
      },
      "source": [
        "{\"class_id\":  \"n02124075\", \"class_name\": \"Egyptian_cat\"}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_id': 'n02124075', 'class_name': 'Egyptian_cat'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlXGT3lV154",
        "colab_type": "text"
      },
      "source": [
        "#### **Step2: Install and import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL6ssaVpVngB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# $ pip install Flask==1.0.3 torchvision-0.3.0\n",
        "from flask import Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def hello():\n",
        "  return 'Hello World!'\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6EITbV2X6RF",
        "colab_type": "text"
      },
      "source": [
        "Save the above snippet in a file called app.py and you can now run a Flask development server by typing:\n",
        "\n",
        "`$ FLASK_ENV=development FLASK_APP=app.py flask run`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c_fQ99mX1Ml",
        "colab_type": "text"
      },
      "source": [
        "When you visit http://localhost:5000/ in your web browser, you will be greeted with Hello World! text\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0zEpUmfEzq",
        "colab_type": "text"
      },
      "source": [
        "### **Step 3: Modifying the Endpoint:**\n",
        "We will make slight changes to the above snippet, so that it suits our API definition. First, we will rename the method to predict. We will update the endpoint path to /predict. Since the image files will be sent via HTTP POST requests, we will update it so that it also accepts only POST requests.\n",
        "\n",
        "\n",
        "We will also change the response type, so that it returns a JSON response containing ImageNet class id and name. The updated app.py file will be now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZtahpAxeOUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh08ugHPeJeJ",
        "colab_type": "text"
      },
      "source": [
        "### **Step 4: Inference**\n",
        "In the next sections we will focus on writing the inference code. This will involve two parts, one where we prepare the image so that it can be fed to DenseNet and next, we will write the code to get the actual prediction from the model.\n",
        "\n",
        "Preparing the image\n",
        "DenseNet model requires the image to be of 3 channel RGB image of size 224 x 224. We will also normalise the image tensor with the required mean and standard deviation values. You can read more about it here.\n",
        "\n",
        "We will use transforms from torchvision library and build a transform pipeline, which transforms our images as required. You can read more about transforms here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8TBXcyPWQGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def transforms_image(image_bytes):\n",
        "  my_transforms = transforms.compose([transforms.Resize(255),\n",
        "                                        transforms.CenterCrop(224),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(\n",
        "                                            [0.485, 0.456, 0.406],\n",
        "                                            [0.229, 0.224, 0.225])])\n",
        "  image = Image.open(io.BytesIO(image_bytes))\n",
        "  return my_transforms(image.unsqueeze(0))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEDOJGf5d5cy",
        "colab_type": "text"
      },
      "source": [
        "The above method takes image data in bytes, applies the series of transforms and returns a tensor. To test the above method, read an image file in bytes mode (first replacing ../_static/img/sample_file.jpeg with the actual path to the file on your computer) and see if you get a tensor back:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UPFHuCDdZHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('path of Image/name.jpg' , 'rb') as f:\n",
        "  image_bytes = f.read()\n",
        "  tensor = transform_image(image_bytes = image_bytes)\n",
        "  print(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEpZu09Ud8f9",
        "colab_type": "text"
      },
      "source": [
        "### **Step 5: Prediction**\n",
        "Now will use a pretrained DenseNet 121 model to predict the image class. We will use one from torchvision library, load the model and get an inference. While we’ll be using a pretrained model in this example, you can use this same approach for your own models. See more about loading your models in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg-b1GZJfoJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbed1edc-3249-4a3d-a6e9-acf9f1fe3bd4"
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "# Make sure to pass `pretrained` as `True` to use the pretrained weights:\n",
        "model = models.densenet121(pretrained = True)\n",
        "\n",
        "# Since we are using our model only for inference, switch to `eval` mode:\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def get_predictions(image_bytes):\n",
        "  tensor = transform_image(image_bytes = image_bytes)\n",
        "  outputs = model.forward(tensor)\n",
        "  _, y_hat = outputs.max(1)\n",
        "  return y_hat"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:01<00:00, 26.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQoA0lV4hEnG",
        "colab_type": "text"
      },
      "source": [
        "The tensor y_hat will contain the index of the predicted class id. However, we need a human readable class name. For that we need a class id to name mapping. Download this file as imagenet_class_index.json and remember where you saved it (or, if you are following the exact steps in this tutorial, save it in tutorials/_static). This file contains the mapping of ImageNet class id to ImageNet class name. We will load this JSON file and get the class name of the predicted index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1BvnDDcgepB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "imagenet_class_index = json.load(open('/Path to JSON File/imagenet_class_index.json'))\n",
        "\n",
        "def get_predictions(image_bytes):\n",
        "  tensor = transform_image(image_bytes = image_bytes)\n",
        "  outputs = model.forward(tensor)\n",
        "  _ , y_hat = outputs.max(1)\n",
        "\n",
        "  predicted_idx = str(y_hat)\n",
        "\n",
        "  return imagenet_class_index[predicted_idx] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITCxUy4PiGsC",
        "colab_type": "text"
      },
      "source": [
        "Before using imagenet_class_index dictionary, first we will convert tensor value to a string value, since the keys in the imagenet_class_index dictionary are strings. \n",
        "We will test our above method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKo5NvNBiAe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('path of Image/name.jpg' , 'rb') as f:\n",
        "  image_bytes = f.read()\n",
        "  prediction = get_predictions(image_bytes)\n",
        "  print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2W8-sGTik50",
        "colab_type": "text"
      },
      "source": [
        "You should get a response like this:\n",
        "\n",
        "      `['n02124075', 'Egyptian_cat']`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1qKIr0GigaB",
        "colab_type": "text"
      },
      "source": [
        "The first item in array is ImageNet class id and second item is the human readable name."
      ]
    }
  ]
}