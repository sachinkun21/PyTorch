{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use Case 1: Handwritten Digit Classification using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachinkun21/PyTorch/blob/master/Use_Case_1_Handwritten_Digit_Classification_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD4qLrn7Sh4I",
        "colab_type": "text"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Can You recognise these characters? Yes they are digits!\n",
        "But how can we make machine recognise them.\n",
        "\n",
        "This is what I am going to demonstrate in this Notebook using pytorch framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NdMlMQmSpxc",
        "colab_type": "text"
      },
      "source": [
        "In the 1st Notebook, we saw a simple use case of PyTorch for writing a neural network from scratch. In this Notebook, we are going to use different utility packages provided within PyTorch i.e.(nn, autograd, optim, torchvision, torchtext, etc.) to build and train neural network.\n",
        "\n",
        "In this use case, we will create a **Multi-Layered Perceptron (MLP)** network for building a handwritten digit classifier. We will make use of the MNIST dataset included in the torchvision package for training and testing our network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWug-b1pTjXh",
        "colab_type": "text"
      },
      "source": [
        "### Data loading and Preprocessing\n",
        "The first step, as with any project you’ll work on, is data preprocessing. We need to transform the raw dataset into tensors and normalize them in a fixed range. The torchvision package provides a utility called transforms which can be used to combine different transformations together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1um6PcbvRY4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "_tasks = transforms.Compose([\n",
        "                             transforms.ToTensor(), \n",
        "                             transforms.Normalize((0.5,), (0.5,))\n",
        "                            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxFnjoKHUaih",
        "colab_type": "text"
      },
      "source": [
        "1. The first transformation converts the raw data into tensor variables \n",
        "2. The second transformation performs normalization using the below operation:\n",
        "                    ```\n",
        "                    x_normalized = x-mean / std\n",
        "                    ```\n",
        "\n",
        "\n",
        "The values 0.5 and 0.5 represent the mean and standard deviation for 3 channels: red, green, and blue.\n",
        "\n",
        "Let's import the dataset now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyePM3a8R8aS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4bc7ce7f-8d27-4e75-89c6-e51f7e94763d"
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# Loading the MNIST Dataset and applying transform function\n",
        "mnist = MNIST(\"data\" , download = True , train = True, transform = _tasks)\n",
        "mnist"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=(0.5,))\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5UrGbHVWBFE",
        "colab_type": "text"
      },
      "source": [
        "Another excellent utility of PyTorch is **DataLoader** iterators which provide the ability to batch, shuffle and load the data in parallel using multiprocessing workers. \n",
        "\n",
        "For the purpose of evaluating our model, we will also partition our data into training and validation sets using SubSetSampler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlSTv5SVzr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJNo5OqYWfMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating training (80%) and Validation (20%) sets\n",
        "split_size = int(0.8 * len(mnist))\n",
        "index_list = list(range(len(mnist)))\n",
        "train_idx , valid_idx = index_list[:split_size], index_list[split_size : ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaIVobyKWlLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating two sampler objects using SubSetRandomSampler utility\n",
        "tr_sampler = SubsetRandomSampler(train_idx)\n",
        "val_sampler= SubsetRandomSampler(valid_idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywXFSaOuXbxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63a8b163-a786-439c-d07c-c0fc59d7c023"
      },
      "source": [
        "# Create iterator Objects for train and valid Datasets\n",
        "train_loader = DataLoader(mnist, batch_size= 256 , sampler = tr_sampler)\n",
        "valid_loader =  DataLoader(mnist , batch_size = 256 , sampler= val_sampler)\n",
        "len(train_loader) , len(valid_loader)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBEleVpwfW6R",
        "colab_type": "text"
      },
      "source": [
        "The neural network architectures in PyTorch can be defined in a class which inherits the properties from the base class from nn package called **Module.**\n",
        "\n",
        "This inheritance from the nn.Module class allows us to implement, access, and call a number of methods easily. We can define all the layers inside the constructor of the class, and the forward propagation steps inside the forward function.\n",
        "\n",
        "- We will define a network with the following layer configurations: [784, 128,10].\n",
        "- This configuration represents the 784 nodes (28*28 pixels) in the input layer, 128 in the hidden layer, and 10 in the output layer.\n",
        "- Inside the forward function, we will use the sigmoid activation function in the hidden layer (which can be accessed from the nn module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl1JGyyeX2fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztKrRq1lYKye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(784,128)\n",
        "    self.output = nn.Linear(128,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "     x = self.hidden(x)\n",
        "     x = F.sigmoid(x)\n",
        "     x = self.output(x)\n",
        "     return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qehtH3yhggSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Model Object\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BebS5jGKgs-D",
        "colab_type": "text"
      },
      "source": [
        "Let's define the loss function and the optimizer using nn and omptim package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLlSKeoKgrlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters() , lr = 0.01 , weight_decay = 1e-6 , momentum = 0.9 , nesterov = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCNgJayShkhD",
        "colab_type": "text"
      },
      "source": [
        "#### **Training the Model**\n",
        "We are now ready to train the model. The core steps will remain the same as we saw earlier: \n",
        "1. Forward Propagation\n",
        "2. Loss Computation\n",
        "3. Backpropagation\n",
        "4. Updating the parameters.\n",
        "\n",
        "We will run the above steps 10 times and call each step as epoch.\n",
        "Let's start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE-WVax5heET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "18021c90-9021-4ea8-f0e2-45b93a1524dc"
      },
      "source": [
        "for epoch in range(1,11):\n",
        "  train_loss, valid_loss = [], []\n",
        "\n",
        "  # Training \n",
        "  model.train()\n",
        "  for data , target in train_loader:\n",
        "      # Flatten MNIST images into a 784 long vector\n",
        "      #data = data.view(data.shape[0], -1)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 1. Forward Propagation\n",
        "      output = model(data)\n",
        "\n",
        "      # 2. Loss Calculation\n",
        "      loss = loss_func(output, target)\n",
        "\n",
        "      # 3. Backward propagation\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Weight Optimization\n",
        "      opitmizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "  # Evaluation \n",
        "  model.eval()\n",
        "  for data, target in valid_loader:\n",
        "    output = model(data)\n",
        "    loss = loss_func(output , target)\n",
        "    valid_loss.append(loss.item())\n",
        "  print(\"Epoch: \" , epoch, \"Training Loss: \", np.mean(train_loss) , \"Validation Loss: \", np.mean(valid_loss))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-d8ab25a6c5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;31m# 1. Forward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m# 2. Loss Calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-6f78646644df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [7168 x 28], m2: [784 x 128] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:197"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJCe-uckiaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data,target in train_loader:\n",
        "  print((data),(target))\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFzKRM9RmUSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "212089a4-0bf5-4996-f71b-0dc2d31eb98b"
      },
      "source": [
        "print(train_loader)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fa3e339fb00>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TSwuFejmXRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-RCfBRU-gSB",
        "colab_type": "text"
      },
      "source": [
        "#### **Predictions**\n",
        "Once the model is trained, make the predictions on the validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfnlFAmOog3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## dataloader for validation dataset \n",
        "dataiter = iter(validloader)\n",
        "data, labels = dataiter.next()\n",
        "output = model(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRdi8ANw-mWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, preds_tensor = torch.max(output, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Xc08wc-qJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Actual:\", labels[:10])\n",
        "print (\"Predicted:\", preds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}