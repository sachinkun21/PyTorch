{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "PyTorch Intro_1.1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachinkun21/PyTorch/blob/master/PyTorch_Intro_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0eBE20yH4TH",
        "colab_type": "text"
      },
      "source": [
        "# What is PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB4W3gERH4TI",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"download.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XPHp1VQH4TK",
        "colab_type": "text"
      },
      "source": [
        "PyTorch is a Python-based scientific computing package that uses the power of graphics processing units(GPU). It is also one of the preferred deep learning research platforms built to provide maximum flexibility and speed. It is known for providing two of the most high-level features; namely, tensor computations with strong GPU acceleration support and building deep neural networks on a tape-based autograd systems.\n",
        "\n",
        "There are many existing Python libraries which have the potential to change how deep learning and artificial intelligence are performed, and this is one such library. One of the key reasons behind PyTorch’s success is it is completely Pythonic and one can build neural network models effortlessly. It is still a young player when compared to its other competitors, however, it is gaining momentum fast."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pFFUNFjH4TL",
        "colab_type": "text"
      },
      "source": [
        "## Brief History about PyTorch\n",
        "\n",
        "Since its release in January 2016, many researchers have continued to increasingly adopt PyTorch. It has quickly become a go-to library because of its ease in building extremely complex neural networks. It is giving a tough competition to TensorFlow especially when used for research work. However, there is still some time before it is adopted by the masses due to its still “new” and “under construction” tags.\n",
        "\n",
        "PyTorch creators envisioned this library to be highly imperative which can allow them to run all the numerical computations quickly. This is an ideal methodology which fits perfectly with the Python programming style. It has allowed deep learning scientists, machine learning developers, and neural network debuggers to run and test part of the code in real time. Thus they don’t have to wait for the entire code to be executed to check whether it works or not.\n",
        "You can always use your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch functionalities and services when required. Now you might ask, why PyTorch? What’ so special in using it to build deep learning models?\n",
        "\n",
        "The answer is quite simple, PyTorch is a dynamic library (very flexible and you can use as per your requirements and changes) which is currently adopted by many of the researchers, students, and artificial intelligence developers. In the recent Kaggle competition, PyTorch library was used by nearly all of the top 10 finishers.\n",
        "\n",
        "Some of the key highlights of PyTorch includes:\n",
        "\n",
        "__Simple Interface:__ It offers easy to use API, thus it is very simple to operate and run like Python.\n",
        "\n",
        "__Pythonic in nature:__ This library, being Pythonic, smoothly integrates with the Python data science stack. Thus it can leverage all the services and functionalities offered by the Python environment.\n",
        "\n",
        "__Computational graphs:__ In addition to this, PyTorch provides an excellent platform which offers dynamic computational graphs, thus you can change them during runtime. This is highly useful when you have no idea how much memory will be required for creating a neural network model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pobCAJpYH4TL",
        "colab_type": "text"
      },
      "source": [
        "### Why we use PyTorch in research field?\n",
        "\n",
        "Anyone who is working in the field of deep learning and artificial intelligence has likely worked with TensorFlow before, Google’s most popular open source library. However, the latest deep learning framework – PyTorch solves major problems in terms of research work. Arguably PyTorch is TensorFlow’s biggest competitor to date, and it is currently a much favored deep learning and artificial intelligence library in the research community.\n",
        "\n",
        "\n",
        "You might be thinking why we use PyTorch? I list down the three factors for that\n",
        "\n",
        "- Using API is Easy: It is as simple as Python.\n",
        "- Pyt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bJzB2JSH4TM",
        "colab_type": "text"
      },
      "source": [
        "### CPU v/s GPU\n",
        "  - CPU have fewer but more powerful compute cores, and whereas GPUs have a large number of lower-performant cores.\n",
        "  - CPUs are more suited to sequential tasks and GPUs are suitable for tasks with significant parallelization.\n",
        "\n",
        "<img src=\"Cpu vs Gpu.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T7D1MLPH4TN",
        "colab_type": "text"
      },
      "source": [
        "### Install\n",
        "\n",
        "<mark style=\"background-color: Blue\">__In CPU__</mark>\n",
        "\n",
        "__For Windows__\n",
        "\n",
        "* Install PyTorch using conda\n",
        "      conda install pytorch torchvision cpuonly -c pytorch\n",
        "\n",
        "* Using pip\n",
        "      pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "        \n",
        "__For Mac__\n",
        "\n",
        "* Using conda\n",
        "      conda install pytorch torchvision -c pytorch\n",
        "    \n",
        "* Using pip\n",
        "      pip3 install torch torchvision\n",
        "    \n",
        "__For Linux__\n",
        "\n",
        "* Using conda\n",
        "      conda install pytorch torchvision cpuonly -c pytorch\n",
        "    \n",
        "* Using pip\n",
        "      pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "      \n",
        "      \n",
        "      \n",
        "<mark style=\"background-color: Green\">__In GPU__</mark>\n",
        "\n",
        "__For Windows__\n",
        "\n",
        "* Install PyTorch using conda cuda=9.2 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=9.2 -c pytorch\n",
        "     \n",
        "* Using conda cuda=10.1 and Python=3.6 \n",
        "      conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
        "     \n",
        "* Install Pytorch using pip cuda=9.2 and Python=3.6\n",
        "      pip3 install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "     \n",
        "* Using pip cuda=10.1 and Python=3.6\n",
        "      pip3 install torch torchvision\n",
        "     \n",
        "__For Linux__\n",
        "\n",
        "* Install PyTorch using conda cuda=9.2 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=9.2 -c pytorch\n",
        "     \n",
        "* Using conda cuda=10.1 and Python=3.6\n",
        "      conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
        "     \n",
        "* Install Pytorch using pip cuda=9.2 and Python=3.6\n",
        "      pip3 install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "     \n",
        "* Using pip cuda=10.1 and Python=3.6\n",
        "      pip3 install torch torchvision\n",
        "     \n",
        "__For Mac__\n",
        "\n",
        "* Install PyTorch using conda  for cuda=9.2 and 10.1 we can use same command and Python=3.6\n",
        "\n",
        "      conda install pytorch torchvision -c pytorch\n",
        "         # MacOS Binaries dont support CUDA, install from source if CUDA is needed\n",
        "       \n",
        "* Install Pytorch using pip for cuda=9.2 and 10.1 we can use same command and Python=3.6\n",
        "\n",
        "      pip3 install torch torchvision\n",
        "         # MacOS Binaries dont support CUDA, install from source if CUDA is needed\n",
        "      \n",
        "You have to run all these commands in __Anaconda Prompt__ , if you want to install in a notebook just put \" ! \" mark before the command like: !pip3 install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfFpyhf-H4TO",
        "colab_type": "text"
      },
      "source": [
        "For more information about Installation you can go through this site : \"https://pytorch.org/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFvmKpOH4TO",
        "colab_type": "text"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensor is similar to Numpy's ndarray, the additional point for Tensors in we can use it in GPUs to accelerate computing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNaercAnH4TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33OgibwvI9Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "630494f3-3438-4d81-b0a2-0d9ab3ad03b2"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWtt7NGHH4TV",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Construct 6x3 matrix, Empty/uninitialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfYipsYrH4TW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4cae6728-3ea8-44d5-aebb-1e3f0e60b8fc"
      },
      "source": [
        "a = torch.empty(6,3)\n",
        "print(a)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.9095e-35, 0.0000e+00, 7.0065e-44],\n",
            "        [6.7262e-44, 6.3058e-44, 6.7262e-44],\n",
            "        [7.5670e-44, 6.3058e-44, 6.7262e-44],\n",
            "        [7.5670e-44, 1.1771e-43, 6.8664e-44],\n",
            "        [7.5670e-44, 8.1275e-44, 7.4269e-44],\n",
            "        [7.0065e-44, 8.1275e-44, 7.0065e-44]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F7cb69EMzkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d94b6abd-bbce-4f9d-c990-580aae97c3a6"
      },
      "source": [
        "torch.empty(2,4,4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3.9094e-35, 0.0000e+00, 7.0065e-44, 6.7262e-44],\n",
              "         [6.3058e-44, 6.7262e-44, 7.5670e-44, 6.3058e-44],\n",
              "         [6.7262e-44, 7.5670e-44, 1.1771e-43, 6.8664e-44],\n",
              "         [7.5670e-44, 8.1275e-44, 7.4269e-44, 7.0065e-44]],\n",
              "\n",
              "        [[8.1275e-44, 7.0065e-44, 7.0065e-44, 6.4460e-44],\n",
              "         [7.8473e-44, 7.2868e-44, 7.2868e-44, 7.8473e-44],\n",
              "         [7.7071e-44, 7.0065e-44, 1.2612e-43, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDDtBrtLJmxl",
        "colab_type": "text"
      },
      "source": [
        "__Note:__ Uninitialized matrix is declared, but doesn't contain definite known values before it is used. When we created an Unintialized matrix, whatever values were allocated inside the memory will apear as the initial values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNrvGO0gH4Ta",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Construct a randomly initialized matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYeVq9EkH4Tb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "158349c5-1b7a-4ff8-b1b0-3213c6e51616"
      },
      "source": [
        "a = torch.rand(4,3)\n",
        "print(a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5074, 0.1786, 0.6250],\n",
            "        [0.3592, 0.6683, 0.5159],\n",
            "        [0.0862, 0.2943, 0.3154],\n",
            "        [0.3766, 0.4469, 0.6244]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3DWEFPnH4Te",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Construct a matrix filled zeros and of dtype long:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRc6kPSEH4Te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7db86c7-34c7-4802-b5df-90485404f48a"
      },
      "source": [
        "a = torch.zeros(4,3, dtype=torch.long)\n",
        "print(a)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyj2OHH0H4Th",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Construct a tensor with pre-defined data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMMgNJ4KH4Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "587fad5d-14d3-4d44-c969-72bcd1ef58a7"
      },
      "source": [
        "a = torch.tensor([7.8, 5])\n",
        "type(a),a"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, tensor([7.8000, 5.0000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3ZJsOyiH4To",
        "colab_type": "text"
      },
      "source": [
        "#### 5. We can also create new tensor with existing tensor. These methods will inherit/reuse the properties of input tensor, e.g. dtype, unless new values are provided manually:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMTy6FhQH4To",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "02682a69-0e8d-4d17-bb4c-c14493f96691"
      },
      "source": [
        "a = a.new_ones(6,5, dtype=torch.double)    # new methods take in sizes\n",
        "print(a)\n",
        "\n",
        "a = torch.randn_like(a, dtype=torch.float)  # override dtype\n",
        "print(a)                                    # result will be the same size"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 5.1738e-01, -4.6653e-01, -2.1396e+00,  7.4822e-02,  1.4868e+00],\n",
            "        [ 3.2157e-02, -1.3188e+00, -1.5774e+00,  8.8414e-04,  2.1188e-01],\n",
            "        [ 1.3376e+00,  1.5126e-01,  7.2339e-01,  2.2358e-01, -1.3040e+00],\n",
            "        [-1.8435e+00, -1.6123e+00,  3.4806e-01,  7.6027e-01, -1.8765e-01],\n",
            "        [-1.5423e-01, -4.1328e-02,  1.5896e+00,  7.3205e-01, -3.6298e-01],\n",
            "        [ 1.1737e-01,  3.9180e-01, -1.3972e-01,  1.2243e+00,  9.6091e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANaole3WH4Tr",
        "colab_type": "text"
      },
      "source": [
        "Let's get the size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3B6q4dzH4Ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b093f54c-a937-4533-b5bf-59a9dd16a1a3"
      },
      "source": [
        "print(a.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ivookYH4Tv",
        "colab_type": "text"
      },
      "source": [
        "Note: <mark style=\"background-color: Yellow\">torch_size</mark> is actually a tuple, so it supports all tuple operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJytavpRH4Tw",
        "colab_type": "text"
      },
      "source": [
        "## Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following examples, we used addition operation,\n",
        "\n",
        "- Addition: syntax1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNBRAoZZH4Tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "92e6c8c5-6b82-4d11-e258-05bce16e9030"
      },
      "source": [
        "b = torch.rand(6,5)\n",
        "print(a + b)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3927,  0.1521, -1.9672,  0.2586,  2.4841],\n",
            "        [ 0.1368, -0.6768, -1.3340,  0.1330,  0.3206],\n",
            "        [ 1.7812,  0.9855,  1.4378,  0.2598, -1.2970],\n",
            "        [-1.0678, -0.8903,  0.6684,  1.5912,  0.1153],\n",
            "        [ 0.3858,  0.2338,  1.8124,  1.4448, -0.1886],\n",
            "        [ 0.3511,  0.9645,  0.4233,  1.9263,  1.8284]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfS2BmkeH4Tz",
        "colab_type": "text"
      },
      "source": [
        "- Addition: syntax2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hpfy8yTH4T0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4ae6290a-9356-457c-bd2b-47f7b9a2ba27"
      },
      "source": [
        "print(torch.add(a,b))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3927,  0.1521, -1.9672,  0.2586,  2.4841],\n",
            "        [ 0.1368, -0.6768, -1.3340,  0.1330,  0.3206],\n",
            "        [ 1.7812,  0.9855,  1.4378,  0.2598, -1.2970],\n",
            "        [-1.0678, -0.8903,  0.6684,  1.5912,  0.1153],\n",
            "        [ 0.3858,  0.2338,  1.8124,  1.4448, -0.1886],\n",
            "        [ 0.3511,  0.9645,  0.4233,  1.9263,  1.8284]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ves3foxkH4T6",
        "colab_type": "text"
      },
      "source": [
        "- Addition: providing an output as an argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5znXdLH4T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "433586eb-a7b8-4fe6-a65a-7a485d717ec0"
      },
      "source": [
        "result = torch.empty(6, 5)\n",
        "torch.add(a, b, out=result)\n",
        "print(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3927,  0.1521, -1.9672,  0.2586,  2.4841],\n",
            "        [ 0.1368, -0.6768, -1.3340,  0.1330,  0.3206],\n",
            "        [ 1.7812,  0.9855,  1.4378,  0.2598, -1.2970],\n",
            "        [-1.0678, -0.8903,  0.6684,  1.5912,  0.1153],\n",
            "        [ 0.3858,  0.2338,  1.8124,  1.4448, -0.1886],\n",
            "        [ 0.3511,  0.9645,  0.4233,  1.9263,  1.8284]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQpWly2NH4T-",
        "colab_type": "text"
      },
      "source": [
        "- Addition: in place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adl-dskfH4T-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6a806b01-8b82-4e22-9af5-1a07a995e803"
      },
      "source": [
        "# adds a to b\n",
        "b.add_(a)\n",
        "print(b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3927,  0.1521, -1.9672,  0.2586,  2.4841],\n",
            "        [ 0.1368, -0.6768, -1.3340,  0.1330,  0.3206],\n",
            "        [ 1.7812,  0.9855,  1.4378,  0.2598, -1.2970],\n",
            "        [-1.0678, -0.8903,  0.6684,  1.5912,  0.1153],\n",
            "        [ 0.3858,  0.2338,  1.8124,  1.4448, -0.1886],\n",
            "        [ 0.3511,  0.9645,  0.4233,  1.9263,  1.8284]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-4rZmNhH4UB",
        "colab_type": "text"
      },
      "source": [
        "__Note:__ Any operation that mutates a tensor in-place is post-fixed with an <mark style=\"background-color: red\">_.</mark> For example: a.copy_(b), a.b_(), will change a."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8UIkasxH4UC",
        "colab_type": "text"
      },
      "source": [
        "#### We can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8iiZKrtH4UD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fbca0bf-755f-4e23-fcd3-003c8b445938"
      },
      "source": [
        "print(a[:,2])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.1396, -1.5774,  0.7234,  0.3481,  1.5896, -0.1397])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7cFd7IfH4UF",
        "colab_type": "text"
      },
      "source": [
        "#### Resizing: We can resize or reshape tensor, using <mark style=\"background-color: Yellow\">tensor.view</mark> :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVFGCMn3H4UG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0220f3e0-e8bf-4215-90ae-d88c60d9420a"
      },
      "source": [
        "a = torch.randn(3, 3)\n",
        "b = a.view(9)\n",
        "c = a.view(-1, 9)  # the size -1 is inferred from other dimensions\n",
        "print(a.size(), b.size(), c.size())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3]) torch.Size([9]) torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeubCh08QZV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "544b5ea6-a9d9-4a20-db8d-cde2360f5f00"
      },
      "source": [
        "a,b,c"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.6204, -2.1548, -0.7342],\n",
              "         [ 2.3593, -2.0394,  0.7926],\n",
              "         [ 0.9949, -0.0726, -1.1585]]),\n",
              " tensor([-1.6204, -2.1548, -0.7342,  2.3593, -2.0394,  0.7926,  0.9949, -0.0726,\n",
              "         -1.1585]),\n",
              " tensor([[-1.6204, -2.1548, -0.7342,  2.3593, -2.0394,  0.7926,  0.9949, -0.0726,\n",
              "          -1.1585]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls1Kk-19H4UK",
        "colab_type": "text"
      },
      "source": [
        "### If you have one value tensor, use <mark style=\"background-color: Yellow\">.item()</mark> to get the value of the Python number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooe7op2RH4UL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a3bfef15-58aa-450d-85c4-998ab2f70faa"
      },
      "source": [
        "a = torch.randn(1)\n",
        "print(a)\n",
        "print(a.item())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.4489])\n",
            "-0.44890645146369934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cArMpWzmH4UO",
        "colab_type": "text"
      },
      "source": [
        "## NumPy Bridge\n",
        "\n",
        "Converting a Torch Tensor to NumPy array and vice versa is breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY1nm63nH4UP",
        "colab_type": "text"
      },
      "source": [
        "__Converting a Torch tensor to NumPy array__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHs_gyjxH4UP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a62081-d9fa-4cfe-8960-627c788c2b99"
      },
      "source": [
        "x = torch.ones(4)\n",
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu7b73iTH4US",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c0bc2e2-cca6-450c-b1cb-aeb0558c008e"
      },
      "source": [
        "y = x.numpy()\n",
        "print(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anD6I7hgRgy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e1952bd-dfd4-461a-ac2a-08decc30cfd3"
      },
      "source": [
        "x"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khvmq2FuH4UU",
        "colab_type": "text"
      },
      "source": [
        "See how numpy array changed in value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHGjvveWH4UV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b11b9efc-6509-4eea-ced5-2dc4c35ca01b"
      },
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2.])\n",
            "[2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxG9QoprH4UX",
        "colab_type": "text"
      },
      "source": [
        "__Converting NumPy array to Torch tensor__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RavfIhuxH4UY",
        "colab_type": "text"
      },
      "source": [
        "lets see how changing the numpy array changed the Torch Tensor automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoUiSozeH4UZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3fe872e-6e63-4898-9b6b-4b5064d0f0a8"
      },
      "source": [
        "import numpy as np\n",
        "f = np.ones(4)\n",
        "g = torch.from_numpy(f)\n",
        "np.add(f, 1, out=f)\n",
        "print(f)\n",
        "print(g)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX0H5ZvFH4Ub",
        "colab_type": "text"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "__CUDA Tensors__\n",
        "\n",
        "Tensors can be moved onto any device using the <mark style=\"background-color: Yellow\">.to</mark> method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rrct32dH4Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b68b4b6-103c-47ba-cfad-4f9e3ddd1f13"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    z = z.to(\"cpu\", torch.double)              # ``.to`` can also change dtype together!\n",
        "    print(z)\n",
        "  \n",
        "else:\n",
        "  print(\"CUDA not Available\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.], device='cuda:0')\n",
            "tensor([3., 3., 3., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlBtenfOH4Uf",
        "colab_type": "text"
      },
      "source": [
        "## AUTOGRAD : Automatic Differentiaition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JYgn2MZH4Ug",
        "colab_type": "text"
      },
      "source": [
        "Definition - \n",
        "\n",
        "  - This class is an engine to calculate derivatives. \n",
        "  - It records the graph of all the operations performed on a gradient enabled tensor and creates a acyclic graph called the dynamic computational graph(DCG).\n",
        "  - The leaves of this graph are input tensors and the roots are output tensors. \n",
        "  - Gradients are calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptzSXZErH4Ug",
        "colab_type": "text"
      },
      "source": [
        "Let us see this in some more easy terms with some examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNkrgYvNH4Uh",
        "colab_type": "text"
      },
      "source": [
        "## Tensor\n",
        "\n",
        "<mark style=\"background-color: Yellow\">torch.Tensor</mark> is the central class of the package.If we set its attribute <mark style=\"background-color: Yellow\">.requires_grad</mark> as <mark style=\"background-color: dark grey\">True</mark>, it starts to track all operations on it. When you finish your computation you can call <mark style=\"background-color: Yellow\">.backward()</mark> and have all the gradients computed automatically. The gradient of this tensor will be accumulated into <mark style=\"background-color: Yellow\">.grad</mark> attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V94-OI6UH4Uh",
        "colab_type": "text"
      },
      "source": [
        "To stop a tensor from tracking history, you can call <mark style=\"background-color: Yellow\">.detach()</mark> to detach it from the computation history, and to prevent future computation from being tracked.\n",
        "\n",
        "\n",
        "To prevent tracking history(and using memory), you can also wrap the code block in with <mark style=\"background-color: Yellow\">torch.no_grad():</mark>. This can be particularly helpful when evaluating a model because the model may have trainable parameters with <mark style=\"background-color: Yellow\">requires_grad=True</mark>, but for which we don’t need the gradients.\n",
        "\n",
        "There's one more class which is very important in autograd implementation - a <mark style=\"background-color: Yellow\">Function</mark>\n",
        "\n",
        "<mark style=\"background-color: Yellow\">Tensor</mark> and <mark style=\"background-color: Yellow\">Function</mark> are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a <mark style=\"background-color: Yellow\">.grad_fn</mark> attribute that references a Function that has created the Tensor (except for Tensors created by the user - their <mark style=\"background-color: Yellow\">grad_fn is None</mark>).\n",
        "\n",
        "If you want to compute the derivatives, you can call <mark style=\"background-color: Yellow\">.backward()</mark> on a <mark style=\"background-color: Yellow\">Tensor</mark>. If <mark style=\"background-color: Yellow\">Tensor</mark> is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to <mark style=\"background-color: Yellow\">backward()</mark>, however if it has more elements, you need to specify a <mark style=\"background-color: Yellow\">gradient</mark> argument that is a tensor of matching shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNyy-6KhH4Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqEpqowqH4Uk",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor and set requires_grad=True to track computation with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryPCHya1H4Ul",
        "colab_type": "code",
        "colab": {},
        "outputId": "c9e7bf8a-a56d-4c7d-cf47-42304684cb3f"
      },
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbBrK8hxH4Un",
        "colab_type": "text"
      },
      "source": [
        "Do a tensor operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmwRCVRNH4Uo",
        "colab_type": "code",
        "colab": {},
        "outputId": "a727defc-ffa3-4a48-b2f1-69aceb096561"
      },
      "source": [
        "b = a + 2\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HImV1fbTH4Uq",
        "colab_type": "text"
      },
      "source": [
        "b was created as a result of an operatio, so it has a <mark style=\"background-color: Yellow\">grad_fn</mark>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zynxKV3rH4Ur",
        "colab_type": "code",
        "colab": {},
        "outputId": "4894f440-f43e-4268-8fb6-63c068e9aca3"
      },
      "source": [
        "print(b.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x000002A19C7DB668>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh_e3v0XH4Uu",
        "colab_type": "text"
      },
      "source": [
        "Do more operation on b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnVkTCmUH4Uv",
        "colab_type": "code",
        "colab": {},
        "outputId": "15d4be4d-9de7-4d4a-a295-806419f69646"
      },
      "source": [
        "c = b * b * 3\n",
        "out = c.mean()\n",
        "\n",
        "print(c, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVxCd-2lH4Ux",
        "colab_type": "text"
      },
      "source": [
        "<mark style=\"background-color: Yellow\">.requires_grad_( ... )</mark>  changes an existing Tensor’s <mark style=\"background-color: Yellow\">requires_grad</mark> flag in-place. The input flag defaults to False if not given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "241_TBYKH4Uy",
        "colab_type": "code",
        "colab": {},
        "outputId": "f92c7182-61b2-4403-c67c-f46f282d01f7"
      },
      "source": [
        "p = torch.randn(3, 3)\n",
        "p = ((p * 3) / (p - 1))\n",
        "print(p.requires_grad)\n",
        "p.requires_grad_(True)\n",
        "print(p.requires_grad)\n",
        "q = (p * p).sum()\n",
        "print(q.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x000002A19C7E04E0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DldSZtl0H4U0",
        "colab_type": "text"
      },
      "source": [
        "## Gradients\n",
        "\n",
        "Let's backdrop now. Because <mark style=\"background-color: magenta\">out</mark> contains a single scalar, <mark style=\"background-color: Yellow\">out.backword</mark> is equivalent to  <mark style=\"background-color: Yellow\">out.backward(torch.tensor(1.))</mark>. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZOgvwMRH4U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsO7A4GQH4U6",
        "colab_type": "text"
      },
      "source": [
        "Print gradients d(out)/dx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "185LX_d1H4U6",
        "colab_type": "code",
        "colab": {},
        "outputId": "4f7d540c-4dde-425e-e005-7968567d1a9f"
      },
      "source": [
        "print(a.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-xF8taGH4U-",
        "colab_type": "text"
      },
      "source": [
        "You should have got a matrix of 4.5. Let’s call the out Tensor “o”. We have that \n",
        "\n",
        "$o= \\frac{1}{4} \\sum c_i $ $c_i= 3(a_i+2)^2$  and $c_i|_{a_i=1}= 27$ . \n",
        "\n",
        "Therefore, $\\frac{\\partial_0}{\\partial a_i}=\\frac{3(x_i+2)}{2}$, \n",
        "\n",
        "hence\n",
        "$\\frac{\\partial_0}{\\partial a_i}|_{a_i=1} = \\frac{9}{2} = 4.5$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osf9hc--H4U_",
        "colab_type": "text"
      },
      "source": [
        "### Mathematically - Jacobians and vectors\n",
        "\n",
        "Mathematically, the autograd class is just a Jacobian-vector product computing engine. A Jacobian matrix in very simple words is a matrix representing all the possible partial derivatives of two vectors. It’s the gradient of a vector with respect to another vector.\n",
        "\n",
        "If a vector X = [x1, x2,….xn] is used to calculate some other vector f(X) = [f1, f2, …. fn] through a function f then the Jacobian matrix (J) simply contains all the partial derivative combinations as follows:\n",
        "\n",
        "<img src=\"jacobian-vector.png\">\n",
        "\n",
        "Above matrix represents the gradient of f(X)with respect to X\n",
        "Suppose a PyTorch gradient enabled tensors X as:\n",
        "X = [x1, x2, ….. xn] (Let this be the weights of some machine learning model)\n",
        "X undergoes some operations to form a vector Y\n",
        "Y = f(X) = [y1, y2, …. ym]\n",
        "Y is then used to calculate a scalar loss l. Suppose a vector v happens to be the gradient of the scalar loss l with respect the vector Y as follows\n",
        "\n",
        "<img src=\"jacob1.png\">       *The vector v is called the grad_tensor and passed to the backward() function as an argument*\n",
        "\n",
        "To get the gradient of the loss l with respect to the weights X the Jacobian matrix J is vector-multiplied with the vector v.\n",
        "\n",
        "<img src=\"jac1.png\"> \n",
        "\n",
        "This method of calculating the Jacobian matrix and multiplying it with a vector v enables the possibility for PyTorch to feed external gradients with ease for even the non-scalar outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NadkdvWCH4U_",
        "colab_type": "text"
      },
      "source": [
        "Now let's have a look at an example of vector-Jacobian product:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeTjQs8aH4VA",
        "colab_type": "code",
        "colab": {},
        "outputId": "7057325a-885d-4ff8-8a54-60908f86c36d"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  622.1337,  1041.7932, -1389.5249], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi1iA3wNH4VE",
        "colab_type": "text"
      },
      "source": [
        "Now in this case y is no longer a scalar.<mark style=\"background-color: Yellow\">torch.autograd(torch.tensor(1.))</mark> could not compute the full Jacobian directly, but if we just want the vector-Jacobian product, simply pass the vector to backward as argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO66u2rAH4VE",
        "colab_type": "code",
        "colab": {},
        "outputId": "5ad6afaf-bfd7-4e5e-bcbb-bf8cacdacb91"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGIGEGR-H4VH",
        "colab_type": "text"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors with <mark style=\"background-color: Yellow\">.requires_grad=True</mark> either by wrapping the code block in with <mark style=\"background-color: Yellow\">torch.no_grad()</mark>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv3AViKYH4VH",
        "colab_type": "code",
        "colab": {},
        "outputId": "49ce602c-ae1b-48c9-9316-899f62341907"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCLryFcmH4VK",
        "colab_type": "text"
      },
      "source": [
        "Or by using .detach() to get a new Tensor with the same content but that does not require gradients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s0L0eJKH4VL",
        "colab_type": "code",
        "colab": {},
        "outputId": "6015803a-167b-4430-d244-c7fcbc1c7200"
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xvX3bMHH4VV",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks\n",
        "\n",
        "We can construct neural networks using the <mark style=\"background-color: Yellow\">torch.nn</mark> package.\n",
        "\n",
        "Now that you had a glimpse of autograd, nn depends on autograd to define models and differentiate them. An nn.Module contains layers, and a method forward(input)that returns the output.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "<img src=\"neural.png\"> \n",
        "\n",
        "\n",
        "### convnet\n",
        "\n",
        "It is a simple feed-forward network. It takes the input,feeds it through several layers one after the other, and then finally gives the output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "- Define the neural network that has some learnable parameters (or weights)\n",
        "- Iterate over a dataset of inputs\n",
        "- Process input through the network\n",
        "- Compute the loss (how far is the output from being correct)\n",
        "- Propagate gradients back into the network’s parameters\n",
        "- Update the weights of the network, typically using a simple update rule: <mark style=\"background-color: light-blue\">weight = weight - learning_rate * gradient</mark>\n",
        "        \n",
        "### Define the network\n",
        "\n",
        "Let's define the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOicmGbDH4VV",
        "colab_type": "code",
        "colab": {},
        "outputId": "20287408-1b0e-419b-c1ba-b633842165a3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class network(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(network, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = mx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = network()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "network(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUjTrqIvH4VZ",
        "colab_type": "text"
      },
      "source": [
        "You just have to define the <mark style=\"background-color: yellow\">forward</mark>,  and the <mark style=\"background-color: yellow\">backward</mark> function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the <mark style=\"background-color: yellow\">forward</mark> function.\n",
        "\n",
        "The learnable parameters of a model are returned by <mark style=\"background-color: yellow\">net.parameters()</mark>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifeQxSieH4VZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "ba03cfa8-5439-4ed4-925d-0b265dbec6bb"
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRxyxfQ9H4Vd",
        "colab_type": "text"
      },
      "source": [
        "Let’s try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. To use this net on the MNIST dataset, please resize the images from the dataset to 32x32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suYcVcbmH4Ve",
        "colab_type": "code",
        "colab": {},
        "outputId": "becf5202-b81a-4689-a1e8-a72aa34a39d9"
      },
      "source": [
        "inp = torch.randn(1, 1, 32, 32)\n",
        "out = net(inp)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0746, -0.0389, -0.0148, -0.0516, -0.0599,  0.1114, -0.0071, -0.0573,\n",
            "         -0.0589, -0.1054]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEPgQ6jpH4Vh",
        "colab_type": "text"
      },
      "source": [
        "Zero the gradient buffers of all parameters and backprops with random gradients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SoP61XSH4Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvg6ggnBH4Vl",
        "colab_type": "text"
      },
      "source": [
        "__Note:__\n",
        "<mark style=\"background-color: yellow\">torch.nn</mark> only supports mini-batches. The entire <mark style=\"background-color: yellow\">torch.nn</mark> package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
        "For example, <mark style=\"background-color: yellow\">nn.Conv2d</mark> will take in a 4D Tensor of <mark style=\"background-color: yellow\">nSamples x nChannels x Height x Width</mark>.\n",
        "If you have a single sample, just use <mark style=\"background-color: yellow\">input.unsqueeze(0)</mark> to add a fake batch dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnAXaWbuH4Vl",
        "colab_type": "text"
      },
      "source": [
        "__At this point, we covered:__\n",
        "- Defined neutral network\n",
        "- Processing input and calling backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6O9xQOvH4Vm",
        "colab_type": "text"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
        "There are several different loss functions under the nn package . A simple loss is: <mark style=\"background-color: yellow\">nn.MSELoss</mark> which computes the mean-squared error between the input and the target.\n",
        "    \n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWV66PIhH4Vn",
        "colab_type": "code",
        "colab": {},
        "outputId": "07289f8f-ff9f-453c-b19d-20211ec38191"
      },
      "source": [
        "output = net(inp)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8201, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgfiAarOH4Vq",
        "colab_type": "text"
      },
      "source": [
        "Now, if you follow loss in the backward direction, using its <mark style=\"background-color: yellow\">.grad_fn</mark>attribute, you will see a graph of computations that looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYc3YyF2H4Vr",
        "colab_type": "text"
      },
      "source": [
        "input  ->   conv2d  ->   relu  ->   maxpool2d  ->   conv2d ->   relu  ->   maxpool2d\n",
        "      \n",
        "      -> view -> linear -> relu -> linear -> relu -> linear\n",
        "      \n",
        "      -> MSELoss\n",
        "      \n",
        "      -> loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAiYzOUH4Vr",
        "colab_type": "text"
      },
      "source": [
        "So, when we call <mark style=\"background-color: yellow\">loss.backward()</mark>, the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient.\n",
        "\n",
        "\n",
        "For illustration, let us follow a few steps <mark style=\"background-color: yellow\">backward</mark>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrG0g859H4Vs",
        "colab_type": "code",
        "colab": {},
        "outputId": "fdfb80d8-901b-4a20-e36c-9e9fd5e328df"
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x000001552B599108>\n",
            "<AddmmBackward object at 0x000001552B5990C8>\n",
            "<AccumulateGrad object at 0x000001552B595308>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJnYI6xkH4Vv",
        "colab_type": "text"
      },
      "source": [
        "### Backprop\n",
        "\n",
        "To backpropagate the error all we have to do is to <mark style=\"background-color: yellow\">loss.backward()</mark>. You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n",
        "\n",
        "\n",
        "Now we shall call <mark style=\"background-color: yellow\">loss.backward()</mark>, and have a look at conv1’s bias gradients before and after the backward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1hmYDycH4Vv",
        "colab_type": "code",
        "colab": {},
        "outputId": "d30f6c59-6e8a-4778-9465-4244220cd3e9"
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([ 0.0048,  0.0182, -0.0052,  0.0043,  0.0079, -0.0025])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Esk-7rXH4Vx",
        "colab_type": "text"
      },
      "source": [
        "### Update the weights\n",
        "\n",
        "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
        "    \n",
        "   <mark style=\"background-color: yellow\"> weight = weight - learning_rate * gradient </mark>\n",
        "   \n",
        "We can implement this using simple Python code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORds9MZHH4Vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdqwEp2fH4V1",
        "colab_type": "text"
      },
      "source": [
        "However, as you use neural networks, you want to use various different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, we built a small package: torch.optim that implements all these methods. Using it is very simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGkA-szNH4V1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(inp)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y2k3ivJH4V4",
        "colab_type": "text"
      },
      "source": [
        "Observe how gradient buffers had to be manually set to zero using <mark style=\"background-color:yellow\">optimizer.zero_grad()</mark>. This is because gradients are accumulated as explained in the <mark style=\"font-color:red\">Backprop</mark> section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgHaK40RH4V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}